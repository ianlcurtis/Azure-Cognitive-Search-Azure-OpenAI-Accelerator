{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Q&A against a SQL Database (Azure SQL, Azure Fabric, Synapse, SQL Managed Instance, etc)"
      ],
      "metadata": {},
      "id": "66ab3cc5-aee4-415a-9391-1e5d37ccaf1d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we know (from the prior Notebook) how to query tabular data on a CSV file, let's try now to keep the data at is source and ask questions directly to a SQL Database.\n",
        "**The goal of this notebook is to demonstrate how a LLM so advanced as GPT-4 can understand a human question and translate that into a SQL query to get the answer. **\n",
        "\n",
        "We will be using the Azure SQL Server that you created on the initial deployment. However the same code below works with **any SQL database like Synapse** for example. ****The server should be created on the Resource Group where the Azure Cognitive Search service is located.\n",
        "**\n",
        "Let's begin..**"
      ],
      "metadata": {},
      "id": "306fc0a9-4044-441d-9ba7-f54f32e6ea9f"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import pyodbc\n",
        "\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.sql_database import SQLDatabase\n",
        "\n",
        "\n",
        "from common.prompts import MSSQL_PROMPT, MSSQL_AGENT_PREFIX, MSSQL_AGENT_FORMAT_INSTRUCTIONS\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1707087176799
        }
      },
      "id": "c1fb79a3-4856-4721-988c-112813690a90"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1707087178129
        }
      },
      "id": "258a6e99-2d4f-4147-b8ee-c64c85296181"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install MS SQL DB driver in your machine"
      ],
      "metadata": {},
      "id": "1e8e0b32-a6b5-4b1c-943d-e57b737213fa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need the driver installed on this compute in order to talk to the SQL DB, so run the below cell once<br>\n",
        "Reference: https://learn.microsoft.com/en-us/sql/connect/odbc/linux-mac/installing-the-microsoft-odbc-driver-for-sql-server?view=sql-server-ver16&tabs=ubuntu18-install%2Calpine17-install%2Cdebian8-install%2Credhat7-13-install%2Crhel7-offline"
      ],
      "metadata": {},
      "id": "9a353df6-0966-4e43-a914-6a2856eb140a"
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo ./download_odbc_driver.sh"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Downloading...\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100   983  100   983    0     0  17553      0 --:--:-- --:--:-- --:--:-- 17553\nOK\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    89  100    89    0     0   2542      0 --:--:-- --:--:-- --:--:--  2542\nUpdating apt-get..\nGet:1 file:/var/nccl-repo-2.2.13-ga-cuda9.2  InRelease\nIgn:1 file:/var/nccl-repo-2.2.13-ga-cuda9.2  InRelease\nGet:2 file:/var/nccl-repo-2.2.13-ga-cuda9.2  Release [574 B]                   \nGet:2 file:/var/nccl-repo-2.2.13-ga-cuda9.2  Release [574 B]                   \nHit:3 http://azure.archive.ubuntu.com/ubuntu focal InRelease                   \nGet:4 http://azure.archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]  \nHit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease             \nHit:6 http://ppa.launchpad.net/git-core/ppa/ubuntu focal InRelease             \nHit:7 http://azure.archive.ubuntu.com/ubuntu focal-backports InRelease         \nGet:8 http://azure.archive.ubuntu.com/ubuntu focal-security InRelease [114 kB] \nGet:9 https://nvidia.github.io/libnvidia-container/stable/ubuntu18.04/amd64  InRelease [1484 B]\nHit:10 https://nvidia.github.io/nvidia-container-runtime/stable/ubuntu18.04/amd64  InRelease\nHit:11 https://nvidia.github.io/nvidia-docker/ubuntu18.04/amd64  InRelease     \nHit:12 https://storage.googleapis.com/tensorflow-serving-apt stable InRelease  \nHit:13 https://packages.microsoft.com/repos/azure-cli focal InRelease          \nHit:14 https://packages.microsoft.com/repos/azurecore focal InRelease          \nGet:15 https://packages.microsoft.com/ubuntu/20.04/prod focal InRelease [3631 B]\nHit:16 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease    \nHit:18 https://apt.repos.intel.com/mkl all InRelease        \nGet:19 http://azure.archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3058 kB]\nGet:20 http://azure.archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1160 kB]\nFetched 4451 kB in 2s (2908 kB/s)                         \nReading package lists... Done\nW: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/microsoft-prod.list:1 and /etc/apt/sources.list.d/mssql-release.list:1\nW: Target Packages (main/binary-armhf/Packages) is configured multiple times in /etc/apt/sources.list.d/microsoft-prod.list:1 and /etc/apt/sources.list.d/mssql-release.list:1\nW: Target Packages (main/binary-arm64/Packages) is configured multiple times in /etc/apt/sources.list.d/microsoft-prod.list:1 and /etc/apt/sources.list.d/mssql-release.list:1\nW: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/microsoft-prod.list:1 and /etc/apt/sources.list.d/mssql-release.list:1\nW: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/microsoft-prod.list:1 and /etc/apt/sources.list.d/mssql-release.list:1\nW: Target CNF (main/cnf/Commands-amd64) is configured multiple times in /etc/apt/sources.list.d/microsoft-prod.list:1 and /etc/apt/sources.list.d/mssql-release.list:1\nW: Target CNF (main/cnf/Commands-all) is configured multiple times in /etc/apt/sources.list.d/microsoft-prod.list:1 and /etc/apt/sources.list.d/mssql-release.list:1\nW: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/microsoft-prod.list:1 and /etc/apt/sources.list.d/mssql-release.list:1\nW: Target Packages (main/binary-armhf/Packages) is configured multiple times in /etc/apt/sources.list.d/microsoft-prod.list:1 and /etc/apt/sources.list.d/mssql-release.list:1\nW: Target Packages (main/binary-arm64/Packages) is configured multiple times in /etc/apt/sources.list.d/microsoft-prod.list:1 and /etc/apt/sources.list.d/mssql-release.list:1\nW: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/microsoft-prod.list:1 and /etc/apt/sources.list.d/mssql-release.list:1\nW: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/microsoft-prod.list:1 and /etc/apt/sources.list.d/mssql-release.list:1\nW: Target CNF (main/cnf/Commands-amd64) is configured multiple times in /etc/apt/sources.list.d/microsoft-prod.list:1 and /etc/apt/sources.list.d/mssql-release.list:1\nW: Target CNF (main/cnf/Commands-all) is configured multiple times in /etc/apt/sources.list.d/microsoft-prod.list:1 and /etc/apt/sources.list.d/mssql-release.list:1\nInstalling msodbcsql18..\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following held packages will be changed:\n  msodbcsql17\nThe following packages will be upgraded:\n  msodbcsql17\n1 upgraded, 0 newly installed, 0 to remove and 178 not upgraded.\nE: Held packages were changed and -y was used without --allow-change-held-packages.\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following NEW packages will be installed:\n  mssql-tools\n0 upgraded, 1 newly installed, 0 to remove and 179 not upgraded.\nNeed to get 211 kB of archives.\nAfter this operation, 0 B of additional disk space will be used.\nGet:1 https://packages.microsoft.com/ubuntu/20.04/prod focal/main amd64 mssql-tools amd64 17.10.1.1-1 [211 kB]\nFetched 211 kB in 0s (2480 kB/s)      \nPreconfiguring packages ...\nSelecting previously unselected package mssql-tools.\n(Reading database ... 140956 files and directories currently installed.)\nPreparing to unpack .../mssql-tools_17.10.1.1-1_amd64.deb ...\nUnpacking mssql-tools (17.10.1.1-1) ...\nSetting up mssql-tools (17.10.1.1-1) ...\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nunixodbc-dev is already the newest version (2.3.11-1).\n0 upgraded, 0 newly installed, 0 to remove and 179 not upgraded.\nDONE\n"
        }
      ],
      "execution_count": 3,
      "metadata": {},
      "id": "65fbffc7-e149-4eb3-a4db-9f114b06f205"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Azure SQL DB with the Covid Tracking CSV Data"
      ],
      "metadata": {},
      "id": "35e30fa1-877d-4d3b-80b0-e17459c1e4f4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Azure SQL Database is currently empty, so we need to fill it up with data. Let's use the same data on the Covid CSV filed we used on the prior Notebook, that way we can compare results and methods. \n",
        "For this, you will need to type below the credentials you used at creation time."
      ],
      "metadata": {},
      "id": "b4352dca-7159-4e41-983d-2c6951cf18db"
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.engine.url import URL\n",
        "\n",
        "db_config = {\n",
        "                'drivername': 'mssql+pyodbc',\n",
        "                'username': os.environ[\"SQL_SERVER_USERNAME\"] +'@'+ os.environ[\"SQL_SERVER_NAME\"],\n",
        "                'password': os.environ[\"SQL_SERVER_PASSWORD\"],\n",
        "                'host': os.environ[\"SQL_SERVER_NAME\"],\n",
        "                'port': 1433,\n",
        "                'database': os.environ[\"SQL_SERVER_DATABASE\"],\n",
        "                'query': {'driver': 'ODBC Driver 17 for SQL Server'}\n",
        "            }\n",
        "\n",
        "# Create a URL object for connecting to the database\n",
        "db_url = URL.create(**db_config)\n",
        "\n",
        "# Print the resulting URL string\n",
        "# print(db_url)\n",
        "\n",
        "# Connect to the Azure SQL Database using the URL string\n",
        "engine = create_engine(db_url)\n",
        "\n",
        "# Test the connection\n",
        "try:\n",
        "    conn = engine.connect()\n",
        "    print(\"Connection successful!\")\n",
        "    result = engine.execute(\"SELECT @@Version\")\n",
        "    for row in result:\n",
        "        print(row)\n",
        "    conn.close()\n",
        "    \n",
        "except OperationalError:\n",
        "    print(\"Connection failed.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Connection successful!\n('Microsoft SQL Azure (RTM) - 12.0.2000.8 \\n\\tJan  3 2024 16:32:18 \\n\\tCopyright (C) 2022 Microsoft Corporation\\n',)\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_12433/2845560204.py:27: RemovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n  result = engine.execute(\"SELECT @@Version\")\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1707087373142
        }
      },
      "id": "26739d89-e075-4098-ab38-92cccf9f9425"
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV file into a pandas dataframe\n",
        "csv_path = \"./data/all-states-history.csv\"\n",
        "df = pd.read_csv(csv_path).fillna(value = 0)\n",
        "\n",
        "# Infer column names and data types\n",
        "column_names = df.columns.tolist()\n",
        "column_types = df.dtypes.to_dict()\n",
        "\n",
        "# Generate SQL statement to create table\n",
        "table_name = 'covidtracking'\n",
        "\n",
        "create_table_sql = f\"CREATE TABLE {table_name} (\"\n",
        "for name, dtype in column_types.items():\n",
        "    if dtype == 'object':\n",
        "        create_table_sql += f\"{name} VARCHAR(MAX), \"\n",
        "    elif dtype == 'int64':\n",
        "        create_table_sql += f\"{name} INT, \"\n",
        "    elif dtype == 'float64':\n",
        "        create_table_sql += f\"{name} FLOAT, \"\n",
        "    elif dtype == 'bool':\n",
        "        create_table_sql += f\"{name} BIT, \"\n",
        "    elif dtype == 'datetime64[ns]':\n",
        "        create_table_sql += f\"{name} DATETIME, \"\n",
        "create_table_sql = create_table_sql[:-2] + \")\"\n",
        "\n",
        "try:\n",
        "    #Createse the table in Azure SQL\n",
        "    engine.execute(create_table_sql)\n",
        "    print(\"Table\",table_name,\"succesfully created\")\n",
        "    # Insert data into SQL Database\n",
        "    lower = 0\n",
        "    upper = 1000\n",
        "    limit = df.shape[0]\n",
        "\n",
        "    while lower < limit:\n",
        "        df[lower:upper].to_sql(table_name, con=engine, if_exists='append', index=False)\n",
        "        print(\"rows:\", lower, \"-\", upper, \"inserted\")\n",
        "        lower = upper\n",
        "        upper = min(upper + 1000, limit)\n",
        "\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Table covidtracking succesfully created\nrows: 0 - 1000 inserted\nrows: 1000 - 2000 inserted\nrows: 2000 - 3000 inserted\nrows: 3000 - 4000 inserted\nrows: 4000 - 5000 inserted\nrows: 5000 - 6000 inserted\nrows: 6000 - 7000 inserted\nrows: 7000 - 8000 inserted\nrows: 8000 - 9000 inserted\nrows: 9000 - 10000 inserted\nrows: 10000 - 11000 inserted\nrows: 11000 - 12000 inserted\nrows: 12000 - 13000 inserted\nrows: 13000 - 14000 inserted\nrows: 14000 - 15000 inserted\nrows: 15000 - 16000 inserted\nrows: 16000 - 17000 inserted\nrows: 17000 - 18000 inserted\nrows: 18000 - 19000 inserted\nrows: 19000 - 20000 inserted\nrows: 20000 - 20780 inserted\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1706813308252
        }
      },
      "id": "acaf202c-33a1-4105-b506-c26f2080c1d8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query with LLM"
      ],
      "metadata": {},
      "id": "33ad46af-11a4-41a6-94af-15509fd9e16c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: We are here using Azure SQL, however the same code will work with Synapse, SQL Managed instance, or any other SQL engine. You just need to provide the right ENV variables and it will connect succesfully."
      ],
      "metadata": {},
      "id": "ea2ef524-565a-4f28-9955-fce0d01bbe21"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create or LLM Langchain object using GPT-4 deployment\n",
        "# Again we need GPT-4. It is necesary in the use of Agents. GPT-35-Turbo will make many mistakes.\n",
        "llm = AzureChatOpenAI(deployment_name=\"gpt-4-32k\", temperature=0, max_tokens=500)#YK"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1707087433136
        }
      },
      "id": "7faef3c0-8166-4f3b-a5e3-d30acfd65fd3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create the db object\n",
        "db = SQLDatabase.from_uri(db_url) #initialize"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1707087440102
        }
      },
      "id": "6cbe650c-9e0a-4209-9595-de13f2f1ee0a"
    },
    {
      "cell_type": "code",
      "source": [
        "# Natural Language question (query)\n",
        "QUESTION = \"How may patients were hospitalized during July 2020 in Texas, and nationwide as the total of all states? Use the hospitalizedIncrease column\""
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1707087446990
        }
      },
      "id": "ae80c022-415e-40d1-b205-1744a3164d70"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SQL Agent"
      ],
      "metadata": {},
      "id": "95052aba-d0c5-4883-a0b6-70c20e236b6a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use an agent now and see how ReAct framework solves the problem."
      ],
      "metadata": {},
      "id": "eb8b1352-d6d7-4319-a0b8-ae7b9c2fd234"
    },
    {
      "cell_type": "code",
      "source": [
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "\n",
        "agent_executor = create_sql_agent(\n",
        "    prefix=MSSQL_AGENT_PREFIX,\n",
        "    format_instructions = MSSQL_AGENT_FORMAT_INSTRUCTIONS,\n",
        "    llm=llm,\n",
        "    toolkit=toolkit,# you provide tools to the agent\n",
        "    top_k=30,\n",
        "    verbose=True #shows intermediate steps\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1707087508250
        }
      },
      "id": "2b51fb36-68b5-4770-b5f1-c042a08e0a0f"
    },
    {
      "cell_type": "code",
      "source": [
        "# As we know by now, Agents use expert/tools. Let's see which are the tools for this SQL Agent\n",
        "agent_executor.agent.allowed_tools"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "['sql_db_query', 'sql_db_schema', 'sql_db_list_tables', 'sql_db_query_checker']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1707087513887
        }
      },
      "id": "21c6c6f5-4a14-403f-a1d0-fe6b0c34a563"
    },
    {
      "cell_type": "code",
      "source": [
        "# And let's see now our clever crafted prompt\n",
        "printmd(agent_executor.agent.llm_chain.prompt.template)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "\n\nYou are an agent designed to interact with a SQL database.\n## Instructions:\n- Given an input question, create a syntactically correct mssql query to run, then look at the results of the query and return the answer.\n- Unless the user specifies a specific number of examples they wish to obtain, **ALWAYS** limit your query to at most 30 results.\n- You can order the results by a relevant column to return the most interesting examples in the database.\n- Never query for all the columns from a specific table, only ask for the relevant columns given the question.\n- You have access to tools for interacting with the database.\n- You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n- DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n- DO NOT MAKE UP AN ANSWER OR USE PRIOR KNOWLEDGE, ONLY USE THE RESULTS OF THE CALCULATIONS YOU HAVE DONE. \n- Your response should be in Markdown. However, **when running  a SQL Query  in \"Action Input\", do not include the markdown backticks**. Those are only for formatting the response, not for executing the command.\n- ALWAYS, as part of your final answer, explain how you got to the answer on a section that starts with: \"Explanation:\". Include the SQL query as part of the explanation section.\n- If the question does not seem related to the database, just return \"I don't know\" as the answer.\n- Only use the below tools. Only use the information returned by the below tools to construct your query and final answer.\n- Do not make up table names, only use the tables returned by any of the tools below.\n\n## Tools:\n\n\n\nsql_db_query: Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\nsql_db_schema: Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3\nsql_db_list_tables: Input is an empty string, output is a comma separated list of tables in the database.\nsql_db_query_checker: Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!\n\n\n\n## Use the following format:\n\nQuestion: the input question you must answer. \nThought: you should always think about what to do. \nAction: the action to take, should be one of [sql_db_query, sql_db_schema, sql_db_list_tables, sql_db_query_checker]. \nAction Input: the input to the action. \nObservation: the result of the action. \n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer. \nFinal Answer: the final answer to the original input question. \n\nExample of Final Answer:\n<=== Beginning of example\n\nAction: query_sql_db\nAction Input: SELECT TOP (10) [death] FROM covidtracking WHERE state = 'TX' AND date LIKE '2020%'\nObservation: [(27437.0,), (27088.0,), (26762.0,), (26521.0,), (26472.0,), (26421.0,), (26408.0,)]\nThought:I now know the final answer\nFinal Answer: There were 27437 people who died of covid in Texas in 2020.\n\nExplanation:\nI queried the `covidtracking` table for the `death` column where the state is 'TX' and the date starts with '2020'. The query returned a list of tuples with the number of deaths for each day in 2020. To answer the question, I took the sum of all the deaths in the list, which is 27437. \nI used the following query\n\n```sql\nSELECT [death] FROM covidtracking WHERE state = 'TX' AND date LIKE '2020%'\"\n```\n===> End of Example\n\n\n\nBegin!\n\nQuestion: {input}\nThought: I should look at the tables in the database to see what I can query.  Then I should query the schema of the most relevant tables.\n{agent_scratchpad}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1707087528687
        }
      },
      "id": "1cae3488-5334-4fbb-ab97-a710af07f966"
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2):\n",
        "    try:\n",
        "        response = agent_executor.run(QUESTION) \n",
        "        break\n",
        "    except Exception as e:\n",
        "        response = str(e)\n",
        "        continue"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\nAction Input: \"\"\u001b[0m\nObservation: \u001b[38;5;200m\u001b[1;3mcovidtracking\u001b[0m\nThought:\u001b[32;1m\u001b[1;3mThe `covidtracking` table seems to be the most relevant one for this question. I should check its schema to see what columns it has.\nAction: sql_db_schema\nAction Input: covidtracking\u001b[0m\nObservation: \u001b[33;1m\u001b[1;3m\nCREATE TABLE covidtracking (\n\tdate VARCHAR(max) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n\tstate VARCHAR(max) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n\tdeath FLOAT(53) NULL, \n\t[deathConfirmed] FLOAT(53) NULL, \n\t[deathIncrease] INTEGER NULL, \n\t[deathProbable] FLOAT(53) NULL, \n\thospitalized FLOAT(53) NULL, \n\t[hospitalizedCumulative] FLOAT(53) NULL, \n\t[hospitalizedCurrently] FLOAT(53) NULL, \n\t[hospitalizedIncrease] INTEGER NULL, \n\t[inIcuCumulative] FLOAT(53) NULL, \n\t[inIcuCurrently] FLOAT(53) NULL, \n\tnegative FLOAT(53) NULL, \n\t[negativeIncrease] INTEGER NULL, \n\t[negativeTestsAntibody] FLOAT(53) NULL, \n\t[negativeTestsPeopleAntibody] FLOAT(53) NULL, \n\t[negativeTestsViral] FLOAT(53) NULL, \n\t[onVentilatorCumulative] FLOAT(53) NULL, \n\t[onVentilatorCurrently] FLOAT(53) NULL, \n\tpositive FLOAT(53) NULL, \n\t[positiveCasesViral] FLOAT(53) NULL, \n\t[positiveIncrease] INTEGER NULL, \n\t[positiveScore] INTEGER NULL, \n\t[positiveTestsAntibody] FLOAT(53) NULL, \n\t[positiveTestsAntigen] FLOAT(53) NULL, \n\t[positiveTestsPeopleAntibody] FLOAT(53) NULL, \n\t[positiveTestsPeopleAntigen] FLOAT(53) NULL, \n\t[positiveTestsViral] FLOAT(53) NULL, \n\trecovered FLOAT(53) NULL, \n\t[totalTestEncountersViral] FLOAT(53) NULL, \n\t[totalTestEncountersViralIncrease] INTEGER NULL, \n\t[totalTestResults] FLOAT(53) NULL, \n\t[totalTestResultsIncrease] INTEGER NULL, \n\t[totalTestsAntibody] FLOAT(53) NULL, \n\t[totalTestsAntigen] FLOAT(53) NULL, \n\t[totalTestsPeopleAntibody] FLOAT(53) NULL, \n\t[totalTestsPeopleAntigen] FLOAT(53) NULL, \n\t[totalTestsPeopleViral] FLOAT(53) NULL, \n\t[totalTestsPeopleViralIncrease] INTEGER NULL, \n\t[totalTestsViral] FLOAT(53) NULL, \n\t[totalTestsViralIncrease] INTEGER NULL\n)\n\n/*\n3 rows from covidtracking table:\ndate\tstate\tdeath\tdeathConfirmed\tdeathIncrease\tdeathProbable\thospitalized\thospitalizedCumulative\thospitalizedCurrently\thospitalizedIncrease\tinIcuCumulative\tinIcuCurrently\tnegative\tnegativeIncrease\tnegativeTestsAntibody\tnegativeTestsPeopleAntibody\tnegativeTestsViral\tonVentilatorCumulative\tonVentilatorCurrently\tpositive\tpositiveCasesViral\tpositiveIncrease\tpositiveScore\tpositiveTestsAntibody\tpositiveTestsAntigen\tpositiveTestsPeopleAntibody\tpositiveTestsPeopleAntigen\tpositiveTestsViral\trecovered\ttotalTestEncountersViral\ttotalTestEncountersViralIncrease\ttotalTestResults\ttotalTestResultsIncrease\ttotalTestsAntibody\ttotalTestsAntigen\ttotalTestsPeopleAntibody\ttotalTestsPeopleAntigen\ttotalTestsPeopleViral\ttotalTestsPeopleViralIncrease\ttotalTestsViral\ttotalTestsViralIncrease\n2021-03-07\tAK\t305.0\t0.0\t0\t0.0\t1293.0\t1293.0\t33.0\t0\t0.0\t0.0\t0.0\t0\t0.0\t0.0\t1660758.0\t0.0\t2.0\t56886.0\t0.0\t0\t0\t0.0\t0.0\t0.0\t0.0\t68693.0\t0.0\t0.0\t0\t1731628.0\t0\t0.0\t0.0\t0.0\t0.0\t0.0\t0\t1731628.0\t0\n2021-03-07\tAL\t10148.0\t7963.0\t-1\t2185.0\t45976.0\t45976.0\t494.0\t0\t2676.0\t0.0\t1931711.0\t2087\t0.0\t0.0\t0.0\t1515.0\t0.0\t499819.0\t392077.0\t408\t0\t0.0\t0.0\t0.0\t0.0\t0.0\t295690.0\t0.0\t0\t2323788.0\t2347\t0.0\t0.0\t119757.0\t0.0\t2323788.0\t2347\t0.0\t0\n2021-03-07\tAR\t5319.0\t4308.0\t22\t1011.0\t14926.0\t14926.0\t335.0\t11\t0.0\t141.0\t2480716.0\t3267\t0.0\t0.0\t2480716.0\t1533.0\t65.0\t324818.0\t255726.0\t165\t0\t0.0\t0.0\t0.0\t81803.0\t0.0\t315517.0\t0.0\t0\t2736442.0\t3380\t0.0\t0.0\t0.0\t481311.0\t0.0\t0\t2736442.0\t3380\n*/\u001b[0m\nThought:\u001b[32;1m\u001b[1;3mThe `covidtracking` table has the columns `date`, `state`, and `hospitalizedIncrease` which are relevant to the question. I will write a query to get the sum of `hospitalizedIncrease` for the state of Texas and for all states during July 2020.\nAction: sql_db_query_checker\nAction Input: \nSELECT SUM(hospitalizedIncrease) as TotalHospitalized\nFROM covidtracking\nWHERE date LIKE '2020-07%' AND state = 'TX'\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3mSELECT SUM(hospitalizedIncrease) as TotalHospitalized\nFROM covidtracking\nWHERE date LIKE '2020-07%' AND state = 'TX'\u001b[0m\nThought:\u001b[32;1m\u001b[1;3mThe query syntax is correct. Now I will run this query to get the total number of patients hospitalized in Texas during July 2020.\nAction: sql_db_query\nAction Input: \nSELECT SUM(hospitalizedIncrease) as TotalHospitalized\nFROM covidtracking\nWHERE date LIKE '2020-07%' AND state = 'TX'\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m[(0,)]\u001b[0m\nThought:\u001b[32;1m\u001b[1;3mThe result indicates that no patients were hospitalized in Texas during July 2020 according to the `hospitalizedIncrease` column. Now I will write a query to get the total number of patients hospitalized in all states during July 2020.\nAction: sql_db_query_checker\nAction Input: \nSELECT SUM(hospitalizedIncrease) as TotalHospitalized\nFROM covidtracking\nWHERE date LIKE '2020-07%'\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3mSELECT SUM(hospitalizedIncrease) as TotalHospitalized\nFROM covidtracking\nWHERE date LIKE '2020-07%'\u001b[0m\nThought:\u001b[32;1m\u001b[1;3mThe query syntax is correct. Now I will run this query to get the total number of patients hospitalized in all states during July 2020.\nAction: sql_db_query\nAction Input: \nSELECT SUM(hospitalizedIncrease) as TotalHospitalized\nFROM covidtracking\nWHERE date LIKE '2020-07%'\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m[(63105,)]\u001b[0m\nThought:\u001b[32;1m\u001b[1;3mI now know the final answer.\nFinal Answer: In July 2020, there were no patients hospitalized in Texas, and 63,105 patients were hospitalized nationwide.\n\nExplanation:\nI queried the `covidtracking` table for the sum of the `hospitalizedIncrease` column where the date starts with '2020-07' and the state is 'TX' for Texas, and without the state condition for nationwide. The queries returned the total number of patients hospitalized in Texas and nationwide during July 2020. \n\nI used the following queries:\n\nFor Texas:\n```sql\nSELECT SUM(hospitalizedIncrease) as TotalHospitalized\nFROM covidtracking\nWHERE date LIKE '2020-07%' AND state = 'TX'\n```\n\nFor Nationwide:\n```sql\nSELECT SUM(hospitalizedIncrease) as TotalHospitalized\nFROM covidtracking\nWHERE date LIKE '2020-07%'\n```\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1707087830862
        }
      },
      "id": "6d7bb8cf-8661-4174-8185-c64b4b20670d"
    },
    {
      "cell_type": "code",
      "source": [
        "printmd(response)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "No patients were hospitalized in Texas during July 2020, and 63105 patients were hospitalized nationwide.\n\nExplanation:\nI queried the `covidtracking` table for the sum of the `hospitalizedIncrease` column where the date starts with '2020-07' and the state is 'TX' for Texas and for all states. The queries returned 0 and 63105 respectively. \nI used the following queries\n\n```sql\nSELECT SUM(hospitalizedIncrease) as TotalHospitalized\nFROM covidtracking\nWHERE date LIKE '2020-07%' AND state = 'TX'\n```\n\n```sql\nSELECT SUM(hospitalizedIncrease) as TotalHospitalized\nFROM covidtracking\nWHERE date LIKE '2020-07%'\n```"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1706813310523
        }
      },
      "id": "f23d2135-2199-474e-ae83-455aefc9b93b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANT NOTE**: If you don't specify the column name on the question, runing the above cell multiple times will yield diferent results some times. <br>\n",
        "The reason is:\n",
        "The column names are ambiguous, hence it is hard even for Humans to discern what are the right columns to use"
      ],
      "metadata": {},
      "id": "cfef208f-321c-490e-a50e-e92602daf125"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary"
      ],
      "metadata": {},
      "id": "56cbc405-26e2-471e-9626-2a0df07f5ddc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we** achieved our goal of Asking a Question in natural language to a dataset located on a SQL Database.  We did this by using purely prompt engineering (Langchain does it for us) and the cognitive power of GPT-4.**\n",
        "\n",
        "This process shows why it is NOT necessary to move the data from its original source as long as the source has an API and a common language we can use to interface with. GPT-4 has been trained on the whole public Github corpus, so it can pretty much understand most of the coding and database query languages that exists out there. "
      ],
      "metadata": {},
      "id": "7381ea5f-7269-4e1f-8b0c-1e2c04bd84c0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEXT\n",
        "\n",
        "The Next Notebook will show you how to **create a custom REACT agent that connects to the internet using BING SEARCH API** to answer questions grounded on search results with citations. Basically a clone of Bing Chat."
      ],
      "metadata": {},
      "id": "02073623-91b4-40d6-8eaf-cb6d9c6a7a9a"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}